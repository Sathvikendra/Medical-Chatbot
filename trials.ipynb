{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b385eeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical Chatbot\n"
     ]
    }
   ],
   "source": [
    "print(\"Medical Chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "656c61dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sathv\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n",
      "c:\\Users\\sathv\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone as LangchainPinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "import pinecone\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.document_loaders import DirectoryLoader,PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import CTransformers\n",
    "from langchain_community.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f90f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=\"pcsk_6Lgu1z_4pAz6zZCrFsnHGq6HaSksKJXcjqSSs9pH1psJPrXppgQ6zhXv4gwMP8yGy7oKn8\"\n",
    "PINECONE_API_ENV=\"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c8ab146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader=DirectoryLoader(data,glob=\"*.pdf\",loader_cls=PyPDFLoader)\n",
    "    documents=loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3c3967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data=load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15457581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d28ab4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks=text_split(extracted_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b7e1491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_huggingface_embedding():\n",
    "    embedding=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72e33b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sathv\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "embeddings=download_huggingface_embedding()\n",
    "vectorstore=FAISS.from_documents(text_chunks,embeddings)\n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# print(\"Loaded:\", model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66e5caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result=embeddings.embed_query(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbb6d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"medical-chatbot\"\n",
    "\n",
    "# Create the index if it doesn't exist\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,  # or the dimension of your embeddings\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\", \n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)\n",
    "os.environ[\"PINECONE_API_KEY\"]=\"pcsk_6Lgu1z_4pAz6zZCrFsnHGq6HaSksKJXcjqSSs9pH1psJPrXppgQ6zhXv4gwMP8yGy7oKn8\"\n",
    "# docsearch=LangchainPinecone.from_texts([t.page_content for t in text_chunks],embeddings,index_name=index_name)\n",
    "docsearch = PineconeVectorStore.from_texts(\n",
    "    [t.page_content for t in text_chunks],\n",
    "    embeddings,\n",
    "    index_name=index_name,\n",
    "    # namespace=\"default\", \n",
    "    pinecone_api_key=PINECONE_API_KEY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e6c51de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='ORGANIZATIONS\\nAmerican Academy of Ophthalmology. 655 Beach Street, PO\\nBox 7424, San Francisco, CA 94120-7424. <http://www.\\neyenet.org>.\\nKEY TERMS\\nAllergen —A substance capable of inducing an\\nallergic response.\\nAllergic reaction—An immune system reaction to\\na substance in the environment; symptoms\\ninclude rash, inflammation, sneezing, itchy watery\\neyes, and runny nose.\\nConjunctiva—The mucous membrane that covers\\nthe white part of the eyes and lines the eyelids.'), Document(page_content='ORGANIZATIONS\\nAmerican Academy of Ophthalmology. 655 Beach Street, PO\\nBox 7424, San Francisco, CA 94120-7424. <http://www.\\neyenet.org>.\\nKEY TERMS\\nAllergen —A substance capable of inducing an\\nallergic response.\\nAllergic reaction—An immune system reaction to\\na substance in the environment; symptoms\\ninclude rash, inflammation, sneezing, itchy watery\\neyes, and runny nose.\\nConjunctiva—The mucous membrane that covers\\nthe white part of the eyes and lines the eyelids.'), Document(page_content='ORGANIZATIONS\\nAmerican Academy of Ophthalmology. 655 Beach Street, PO\\nBox 7424, San Francisco, CA 94120-7424. <http://www.\\neyenet.org>.\\nKEY TERMS\\nAllergen —A substance capable of inducing an\\nallergic response.\\nAllergic reaction—An immune system reaction to\\na substance in the environment; symptoms\\ninclude rash, inflammation, sneezing, itchy watery\\neyes, and runny nose.\\nConjunctiva—The mucous membrane that covers\\nthe white part of the eyes and lines the eyelids.')]\n"
     ]
    }
   ],
   "source": [
    "# docsearch=LangchainPinecone.from_existing_index(index,embeddings)\n",
    "query=\"What are Allergies\"\n",
    "docs=docsearch.similarity_search(query,k=3)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8de03709",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer user's questions\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer\n",
    "Context:{context}\n",
    "Question:{question}\n",
    "Only return helpful answers and nothing else\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5564bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(template=prompt_template,input_variables=[\"context\",\"question\"])\n",
    "chain_type_kwargs={\"prompt\":prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d131ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(model=\"model/llama-2-13b-chat.ggmlv3.q6_K.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.8})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78ebcd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Pinecone\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings  # Or your embedding\n",
    "from langchain_community.llms import LlamaCpp  # Or whatever LLM you are using\n",
    "\n",
    "# Assuming `docsearch` is your Pinecone vectorstore\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "# Define chain_type_kwargs only if needed (like for prompt template)\n",
    "chain_type_kwargs = {}  # or your actual kwargs\n",
    "\n",
    "# Create the RetrievalQA chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,    \n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f8fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathv\\AppData\\Local\\Temp\\ipykernel_37668\\2008814045.py:3: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  result=qa({\"query\":user_input})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:  Acne is a chronic inflammatory disease of the pilosebaceous gland.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of tokens (513) exceeded maximum context length (512).\n",
      "Number of tokens (514) exceeded maximum context length (512).\n",
      "Number of tokens (515) exceeded maximum context length (512).\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input=input(f\"Input prompt:\")\n",
    "    result=qa({\"query\":user_input})\n",
    "    print(\"Response:\",result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3050764d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
