{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b385eeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical Chatbot\n"
     ]
    }
   ],
   "source": [
    "print(\"Medical Chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656c61dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sathv\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n",
      "c:\\Users\\sathv\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone as LangchainPinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "import pinecone\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.document_loaders import DirectoryLoader,PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import CTransformers\n",
    "from langchain_community.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c8ab146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader=DirectoryLoader(data,glob=\"*.pdf\",loader_cls=PyPDFLoader)\n",
    "    documents=loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3c3967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data=load_pdf(r\"C:\\Users\\sathv\\Medical-Chatbot\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15457581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=20)\n",
    "    text_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d28ab4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks=text_split(extracted_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b7e1491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_huggingface_embedding():\n",
    "    embedding=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72e33b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sathv\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "embeddings=download_huggingface_embedding()\n",
    "vectorstore=FAISS.from_documents(text_chunks,embeddings)\n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# print(\"Loaded:\", model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66e5caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result=embeddings.embed_query(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9361cae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=\"pcsk_6Lgu1z_4pAz6zZCrFsnHGq6HaSksKJXcjqSSs9pH1psJPrXppgQ6zhXv4gwMP8yGy7oKn8\"\n",
    "PINECONE_API_ENV=\"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbb6d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"medical-chatbot\"\n",
    "\n",
    "# Create the index if it doesn't exist\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,  # or the dimension of your embeddings\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\", \n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)\n",
    "os.environ[\"PINECONE_API_KEY\"]=\"pcsk_6Lgu1z_4pAz6zZCrFsnHGq6HaSksKJXcjqSSs9pH1psJPrXppgQ6zhXv4gwMP8yGy7oKn8\"\n",
    "# docsearch=LangchainPinecone.from_texts([t.page_content for t in text_chunks],embeddings,index_name=index_name)\n",
    "docsearch = PineconeVectorStore.from_texts(\n",
    "    [t.page_content for t in text_chunks],\n",
    "    embeddings,\n",
    "    index_name=index_name,\n",
    "    # namespace=\"default\", \n",
    "    pinecone_api_key=PINECONE_API_KEY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e6c51de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='ORGANIZATIONS\\nAmerican Academy of Ophthalmology. 655 Beach Street, PO\\nBox 7424, San Francisco, CA 94120-7424. <http://www.\\neyenet.org>.\\nKEY TERMS\\nAllergen —A substance capable of inducing an\\nallergic response.\\nAllergic reaction—An immune system reaction to\\na substance in the environment; symptoms\\ninclude rash, inflammation, sneezing, itchy watery\\neyes, and runny nose.\\nConjunctiva—The mucous membrane that covers\\nthe white part of the eyes and lines the eyelids.'), Document(page_content='ORGANIZATIONS\\nAmerican Academy of Ophthalmology. 655 Beach Street, PO\\nBox 7424, San Francisco, CA 94120-7424. <http://www.\\neyenet.org>.\\nKEY TERMS\\nAllergen —A substance capable of inducing an\\nallergic response.\\nAllergic reaction—An immune system reaction to\\na substance in the environment; symptoms\\ninclude rash, inflammation, sneezing, itchy watery\\neyes, and runny nose.\\nConjunctiva—The mucous membrane that covers\\nthe white part of the eyes and lines the eyelids.'), Document(page_content='ORGANIZATIONS\\nAmerican Academy of Ophthalmology. 655 Beach Street, PO\\nBox 7424, San Francisco, CA 94120-7424. <http://www.\\neyenet.org>.\\nKEY TERMS\\nAllergen —A substance capable of inducing an\\nallergic response.\\nAllergic reaction—An immune system reaction to\\na substance in the environment; symptoms\\ninclude rash, inflammation, sneezing, itchy watery\\neyes, and runny nose.\\nConjunctiva—The mucous membrane that covers\\nthe white part of the eyes and lines the eyelids.')]\n"
     ]
    }
   ],
   "source": [
    "# docsearch=LangchainPinecone.from_existing_index(index,embeddings)\n",
    "query=\"What are Allergies\"\n",
    "docs=docsearch.similarity_search(query,k=3)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8de03709",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer user's questions\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer\n",
    "Context:{context}\n",
    "Question:{question}\n",
    "Only return helpful answers and nothing else\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5564bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(template=prompt_template,input_variables=[\"context\",\"question\"])\n",
    "chain_type_kwargs={\"prompt\":prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d131ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(model=r\"C:\\Users\\sathv\\Medical-Chatbot\\model\\llama-2-13b-chat.ggmlv3.q6_K.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.8})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78ebcd96",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for RetrievalQA\nretriever\n  Can't instantiate abstract class BaseRetriever with abstract methods _aget_relevant_documents, _get_relevant_documents (type=type_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vectorstore\u001b[38;5;241m.\u001b[39mas_retriever(search_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m, search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3\u001b[39m})\n\u001b[0;32m      8\u001b[0m chain_type_kwargs \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# or your actual kwargs\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m qa \u001b[38;5;241m=\u001b[39m \u001b[43mRetrievalQA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_chain_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretriever\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstuff\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_source_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain_type_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchain_type_kwargs\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sathv\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\chains\\retrieval_qa\\base.py:95\u001b[0m, in \u001b[0;36mBaseRetrievalQA.from_chain_type\u001b[1;34m(cls, llm, chain_type, chain_type_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m _chain_type_kwargs \u001b[38;5;241m=\u001b[39m chain_type_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m     92\u001b[0m combine_documents_chain \u001b[38;5;241m=\u001b[39m load_qa_chain(\n\u001b[0;32m     93\u001b[0m     llm, chain_type\u001b[38;5;241m=\u001b[39mchain_type, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_chain_type_kwargs\n\u001b[0;32m     94\u001b[0m )\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcombine_documents_chain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_documents_chain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sathv\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\langchain\\load\\serializable.py:74\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32mc:\\Users\\sathv\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\pydantic\\main.py:347\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for RetrievalQA\nretriever\n  Can't instantiate abstract class BaseRetriever with abstract methods _aget_relevant_documents, _get_relevant_documents (type=type_error)"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Pinecone\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings  # Or your embedding\n",
    "from langchain_community.llms import LlamaCpp  # Or whatever LLM you are using\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "chain_type_kwargs = {}  # or your actual kwargs\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,    \n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f8fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathv\\AppData\\Local\\Temp\\ipykernel_37668\\2008814045.py:3: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  result=qa({\"query\":user_input})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:  Acne is a chronic inflammatory disease of the pilosebaceous gland.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of tokens (513) exceeded maximum context length (512).\n",
      "Number of tokens (514) exceeded maximum context length (512).\n",
      "Number of tokens (515) exceeded maximum context length (512).\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input=input(f\"Input prompt:\")\n",
    "    result=qa({\"query\":user_input})\n",
    "    print(\"Response:\",result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3050764d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
